{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Conv2DTranspose, Concatenate, add, BatchNormalization, Activation\n",
    "import os\n",
    "import glob\n",
    "import rasterio\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(x, filters, batchnorm=True):\n",
    "    conv1 = Conv2D(filters, (3, 3), kernel_initializer='he_normal', padding='same')(x)\n",
    "    if batchnorm is True:\n",
    "        conv1 = BatchNormalization(axis=3)(conv1)\n",
    "    conv1 = Activation('relu')(conv1)    \n",
    "    conv2 = Conv2D(filters, (3, 3), kernel_initializer='he_normal', padding='same')(conv1)\n",
    "    if batchnorm is True:\n",
    "        conv2 = BatchNormalization(axis=3)(conv2)\n",
    "    conv2 = Activation(\"relu\")(conv2)\n",
    "\n",
    "    return conv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_conv_block(x, filters, batchnorm=True):\n",
    "    conv1 = Conv2D(filters, (3, 3), kernel_initializer='he_normal', padding='same')(x)\n",
    "    if batchnorm is True:\n",
    "        conv1 = BatchNormalization(axis=3)(conv1)\n",
    "    conv1 = Activation('relu')(conv1)    \n",
    "    conv2 = Conv2D(filters, (3, 3), kernel_initializer='he_normal', padding='same')(conv1)\n",
    "    if batchnorm is True:\n",
    "        conv2 = BatchNormalization(axis=3)(conv2)\n",
    "    conv2 = Activation(\"relu\")(conv2)\n",
    "        \n",
    "    #skip connection    \n",
    "    shortcut = Conv2D(filters, kernel_size=(1, 1), kernel_initializer='he_normal', padding='same')(x)\n",
    "    if batchnorm is True:\n",
    "        shortcut = BatchNormalization(axis=3)(shortcut)\n",
    "    shortcut = Activation(\"relu\")(shortcut)\n",
    "    respath = add([shortcut, conv2])       \n",
    "    return respath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_block(inputs, num_filters):\n",
    "    conv1 = conv_block(inputs, num_filters)\n",
    "    concat = Concatenate()([inputs, conv1])\n",
    "    return concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_unet(input_shape, num_classes):\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    # Encoder\n",
    "    conv1 = residual_conv_block(inputs, 64)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = residual_conv_block(pool1, 128)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = residual_conv_block(pool2, 256)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = residual_conv_block(pool3, 512)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    \n",
    "    # Bottleneck\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', kernel_initializer='he_normal', padding='same')(pool4)\n",
    "    conv5 = Conv2D(1024, (3, 3), kernel_initializer='he_normal', padding='same')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "    \n",
    "    # Decoder\n",
    "    up6 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(drop5)\n",
    "    up6 = Concatenate()([up6, conv4])\n",
    "    conv6 = residual_conv_block(up6, 512)\n",
    "    up7 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv6)\n",
    "    up7 = Concatenate()([up7, conv3])\n",
    "    conv7 = residual_conv_block(up7, 256)\n",
    "    up8 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv7)\n",
    "    up8 = Concatenate()([up8, conv2])\n",
    "    conv8 = residual_conv_block(up8, 128)\n",
    "    up9 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv8)\n",
    "    up9 = Concatenate()([up9, conv1])\n",
    "    conv9 = residual_conv_block(up9, 64)\n",
    "    \n",
    "    # Output\n",
    "    outputs = Conv2D(num_classes, 1, activation='softmax')(conv9)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_unet(input_shape, num_classes):\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    # Encoder\n",
    "    conv1 = dense_block(inputs, 64)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = dense_block(pool1, 128)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = dense_block(pool2, 256)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = dense_block(pool3, 512)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    # Bottleneck\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', kernel_initializer='he_normal', padding='same')(pool4)\n",
    "    conv5 = Conv2D(1024, (3, 3), kernel_initializer='he_normal', padding='same')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "    \n",
    "    # Decoder\n",
    "    up6 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(drop5)\n",
    "    up6 = Concatenate()([up6, conv4])\n",
    "    conv6 = residual_conv_block(up6, 512)\n",
    "    up7 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv6)\n",
    "    up7 = Concatenate()([up7, conv3])\n",
    "    conv7 = residual_conv_block(up7, 256)\n",
    "    up8 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv7)\n",
    "    up8 = Concatenate()([up8, conv2])\n",
    "    conv8 = residual_conv_block(up8, 128)\n",
    "    up9 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv8)\n",
    "    up9 = Concatenate()([up9, conv1])\n",
    "    conv9 = residual_conv_block(up9, 64)\n",
    "    \n",
    "    # Output\n",
    "    outputs = Conv2D(num_classes, 1, activation='softmax')(conv9)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(input_dir, mask_dir):\n",
    "    input_files = sorted(glob.glob(os.path.join(input_dir, '*.tif')))\n",
    "    mask_files = sorted(glob.glob(os.path.join(mask_dir, '*.tif')))\n",
    "    images = []\n",
    "    masks = []\n",
    "\n",
    "    for input_file, mask_file in zip(input_files, mask_files):\n",
    "        # Read input file\n",
    "        with rasterio.open(input_file) as src:\n",
    "            img = src.read(2)  # Read the first band assuming it's a single-band image\n",
    "            # print(img)\n",
    "            images.append(img)\n",
    "\n",
    "        # Read mask file\n",
    "        with rasterio.open(mask_file) as src:\n",
    "            msk = src.read(1)  # Read the first band assuming it's a single-band image\n",
    "            masks.append(msk)\n",
    "\n",
    "    return np.array(images), np.array(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images\n",
      "[[[0.03850178 0.0394277  0.04185019 ... 0.05080734 0.04912348 0.05062708]\n",
      "  [0.04004565 0.03974563 0.04127562 ... 0.04777289 0.04718909 0.05001535]\n",
      "  [0.04139828 0.04110415 0.0415015  ... 0.04294866 0.0436424  0.0485488 ]\n",
      "  ...\n",
      "  [0.04794572 0.03757069 0.03864455 ... 0.03271767 0.03207743 0.03048064]\n",
      "  [0.03332274 0.02812962 0.03361928 ... 0.04048121 0.03828616 0.03472147]\n",
      "  [0.0267618  0.02612066 0.03139854 ... 0.04327314 0.04018223 0.03590726]]\n",
      "\n",
      " [[0.08710568 0.09416492 0.09497649 ... 0.00826482 0.00855915 0.00990077]\n",
      "  [0.0897772  0.09723881 0.09654529 ... 0.00897474 0.00948931 0.01106049]\n",
      "  [0.08326224 0.09220129 0.09141164 ... 0.01007854 0.01025462 0.01163389]\n",
      "  ...\n",
      "  [0.03359238 0.0360279  0.03748187 ... 0.04722763 0.04130829 0.03689655]\n",
      "  [0.03186584 0.03466028 0.03640364 ... 0.04571833 0.04240851 0.03832721]\n",
      "  [0.03209388 0.03441574 0.03619102 ... 0.03970888 0.03619634 0.0340551 ]]\n",
      "\n",
      " [[0.0320792  0.03503213 0.0461979  ... 0.0459112  0.04632825 0.04909702]\n",
      "  [0.04015223 0.04226902 0.04911362 ... 0.04835976 0.04939648 0.05133235]\n",
      "  [0.05055046 0.05043305 0.05200621 ... 0.04798632 0.0493407  0.04939288]\n",
      "  ...\n",
      "  [0.01846429 0.02083568 0.02744074 ... 0.1520016  0.1528863  0.15293364]\n",
      "  [0.0180032  0.02045168 0.02757001 ... 0.13659093 0.13624014 0.13540317]\n",
      "  [0.0182901  0.02072868 0.02688751 ... 0.11406546 0.11328527 0.11265636]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.05572664 0.0613749  0.06260454 ... 0.05923213 0.06092502 0.05903763]\n",
      "  [0.05627395 0.06103162 0.06096114 ... 0.05701005 0.05794028 0.05712898]\n",
      "  [0.05213642 0.05632294 0.0563292  ... 0.0572258  0.0582679  0.05770848]\n",
      "  ...\n",
      "  [0.03320521 0.03281525 0.03310965 ... 0.03684499 0.03967602 0.04162074]\n",
      "  [0.03129057 0.03184647 0.03299677 ... 0.03394324 0.03519367 0.03885612]\n",
      "  [0.03271639 0.03480408 0.03714987 ... 0.03464739 0.03404083 0.03718348]]\n",
      "\n",
      " [[0.0380769  0.04054381 0.04558532 ... 0.04546668 0.05130716 0.05635414]\n",
      "  [0.03757921 0.03812429 0.04150571 ... 0.03494032 0.04181254 0.04825162]\n",
      "  [0.04243899 0.04200014 0.04176114 ... 0.02819573 0.03551158 0.04336419]\n",
      "  ...\n",
      "  [0.03322029 0.03315017 0.0327738  ... 0.06362376 0.06661722 0.06692525]\n",
      "  [0.0357737  0.03563513 0.03518992 ... 0.06634572 0.07113085 0.07098766]\n",
      "  [0.03873625 0.03792338 0.03604088 ... 0.06427335 0.06999216 0.07053781]]\n",
      "\n",
      " [[0.07292883 0.06627065 0.05604517 ... 0.05246096 0.05737552 0.06250033]\n",
      "  [0.07730916 0.06936689 0.05894982 ... 0.05788202 0.05924468 0.05908555]\n",
      "  [0.07745641 0.0709585  0.06129742 ... 0.06275003 0.06267859 0.05927112]\n",
      "  ...\n",
      "  [0.04646982 0.04477111 0.04362733 ... 0.         0.         0.        ]\n",
      "  [0.04534103 0.0438619  0.0422402  ... 0.         0.         0.        ]\n",
      "  [0.04502403 0.0442984  0.04342866 ... 0.         0.         0.        ]]]\n",
      "(7501, 10001, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "A `Concatenate` layer requires inputs with matching shapes except for the concatenation axis. Received: input_shape=[(None, 936, 1250, 512), (None, 937, 1250, 512)]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# Assuming binary segmentation, adjust accordingly if needed\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Create and compile the model\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m model \u001b[38;5;241m=\u001b[39m residual_unet(input_shape, num_classes)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(layer\u001b[38;5;241m.\u001b[39moutput_shape)\n",
      "Cell \u001b[1;32mIn[13], line 21\u001b[0m, in \u001b[0;36mresidual_unet\u001b[1;34m(input_shape, num_classes)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Decoder\u001b[39;00m\n\u001b[0;32m     20\u001b[0m up6 \u001b[38;5;241m=\u001b[39m Conv2DTranspose(\u001b[38;5;241m512\u001b[39m, (\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m), strides\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m), padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m)(drop5)\n\u001b[1;32m---> 21\u001b[0m up6 \u001b[38;5;241m=\u001b[39m Concatenate()([up6, conv4])\n\u001b[0;32m     22\u001b[0m conv6 \u001b[38;5;241m=\u001b[39m residual_conv_block(up6, \u001b[38;5;241m512\u001b[39m)\n\u001b[0;32m     23\u001b[0m up7 \u001b[38;5;241m=\u001b[39m Conv2DTranspose(\u001b[38;5;241m256\u001b[39m, (\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m), strides\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m), padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m)(conv6)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\conda\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\conda\\Lib\\site-packages\\keras\\src\\layers\\merging\\concatenate.py:131\u001b[0m, in \u001b[0;36mConcatenate.build\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    125\u001b[0m unique_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\n\u001b[0;32m    126\u001b[0m     shape[axis]\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m shape \u001b[38;5;129;01min\u001b[39;00m shape_set\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shape[axis] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    129\u001b[0m )\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_dims) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 131\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err_msg)\n",
      "\u001b[1;31mValueError\u001b[0m: A `Concatenate` layer requires inputs with matching shapes except for the concatenation axis. Received: input_shape=[(None, 936, 1250, 512), (None, 937, 1250, 512)]"
     ]
    }
   ],
   "source": [
    "input_dir = './data/'\n",
    "mask_dir = './output_tif/'\n",
    "\n",
    "# Load data\n",
    "images, masks = load_data(input_dir, mask_dir)\n",
    "\n",
    "# Define input shape and number of classes\n",
    "print(\"Images\")\n",
    "print(images)\n",
    "images = np.expand_dims(images, axis=-1)\n",
    "input_shape = images.shape[1:]\n",
    "print(input_shape)\n",
    "num_classes = 1  # Assuming binary segmentation, adjust accordingly if needed\n",
    "\n",
    "# Create and compile the model\n",
    "model = residual_unet(input_shape, num_classes)\n",
    "for layer in model.layers:\n",
    "    print(layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(images, masks, epochs=10, batch_size=4)  # Adjust epochs and batch size as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(images, masks)\n",
    "\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
