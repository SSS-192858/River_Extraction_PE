{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Conv2DTranspose, Concatenate, add, BatchNormalization, Activation\n",
    "import os\n",
    "import glob\n",
    "import rasterio\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(x, filters, batchnorm=True):\n",
    "    conv1 = Conv2D(filters, (3, 3), kernel_initializer='he_normal', padding='same')(x)\n",
    "    if batchnorm is True:\n",
    "        conv1 = BatchNormalization(axis=3)(conv1)\n",
    "    conv1 = Activation('relu')(conv1)    \n",
    "    conv2 = Conv2D(filters, (3, 3), kernel_initializer='he_normal', padding='same')(conv1)\n",
    "    if batchnorm is True:\n",
    "        conv2 = BatchNormalization(axis=3)(conv2)\n",
    "    conv2 = Activation(\"relu\")(conv2)\n",
    "\n",
    "    return conv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_conv_block(x, filters, batchnorm=True):\n",
    "    conv1 = Conv2D(filters, (3, 3), kernel_initializer='he_normal', padding='same')(x)\n",
    "    if batchnorm is True:\n",
    "        conv1 = BatchNormalization(axis=3)(conv1)\n",
    "    conv1 = Activation('relu')(conv1)    \n",
    "    conv2 = Conv2D(filters, (3, 3), kernel_initializer='he_normal', padding='same')(conv1)\n",
    "    if batchnorm is True:\n",
    "        conv2 = BatchNormalization(axis=3)(conv2)\n",
    "    conv2 = Activation(\"relu\")(conv2)\n",
    "        \n",
    "    #skip connection    \n",
    "    shortcut = Conv2D(filters, kernel_size=(1, 1), kernel_initializer='he_normal', padding='same')(x)\n",
    "    if batchnorm is True:\n",
    "        shortcut = BatchNormalization(axis=3)(shortcut)\n",
    "    shortcut = Activation(\"relu\")(shortcut)\n",
    "    respath = add([shortcut, conv2])       \n",
    "    return respath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_block(inputs, num_filters):\n",
    "    conv1 = conv_block(inputs, num_filters)\n",
    "    concat = Concatenate()([inputs, conv1])\n",
    "    return concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_unet(input_shape, num_classes):\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    # Encoder\n",
    "    conv1 = residual_conv_block(inputs, 64)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = residual_conv_block(pool1, 128)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = residual_conv_block(pool2, 256)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = residual_conv_block(pool3, 512)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    \n",
    "    # Bottleneck\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', kernel_initializer='he_normal', padding='same')(pool4)\n",
    "    conv5 = Conv2D(1024, (3, 3), kernel_initializer='he_normal', padding='same')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "    \n",
    "    # Decoder\n",
    "    up6 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(drop5)\n",
    "    up6 = Concatenate()([up6, conv4])\n",
    "    conv6 = residual_conv_block(up6, 512)\n",
    "    up7 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv6)\n",
    "    up7 = Concatenate()([up7, conv3])\n",
    "    conv7 = residual_conv_block(up7, 256)\n",
    "    up8 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv7)\n",
    "    up8 = Concatenate()([up8, conv2])\n",
    "    conv8 = residual_conv_block(up8, 128)\n",
    "    up9 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv8)\n",
    "    up9 = Concatenate()([up9, conv1])\n",
    "    conv9 = residual_conv_block(up9, 64)\n",
    "    \n",
    "    # Output\n",
    "    outputs = Conv2D(num_classes, 1, activation='softmax')(conv9)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_unet(input_shape, num_classes):\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    # Encoder\n",
    "    conv1 = dense_block(inputs, 64)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = dense_block(pool1, 128)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = dense_block(pool2, 256)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = dense_block(pool3, 512)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    # Bottleneck\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', kernel_initializer='he_normal', padding='same')(pool4)\n",
    "    conv5 = Conv2D(1024, (3, 3), kernel_initializer='he_normal', padding='same')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "    \n",
    "    # Decoder\n",
    "    up6 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(drop5)\n",
    "    up6 = Concatenate()([up6, conv4])\n",
    "    conv6 = residual_conv_block(up6, 512)\n",
    "    up7 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv6)\n",
    "    up7 = Concatenate()([up7, conv3])\n",
    "    conv7 = residual_conv_block(up7, 256)\n",
    "    up8 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv7)\n",
    "    up8 = Concatenate()([up8, conv2])\n",
    "    conv8 = residual_conv_block(up8, 128)\n",
    "    up9 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv8)\n",
    "    up9 = Concatenate()([up9, conv1])\n",
    "    conv9 = residual_conv_block(up9, 64)\n",
    "    \n",
    "    # Output\n",
    "    outputs = Conv2D(num_classes, 1, activation='softmax')(conv9)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(input_dir, mask_dir):\n",
    "    input_files = sorted(glob.glob(os.path.join(input_dir, '*.tif')))\n",
    "    # print(input_files)\n",
    "    mask_files = sorted(glob.glob(os.path.join(mask_dir, '*.tif')))\n",
    "    # print(mask_files)\n",
    "    images = []\n",
    "    masks = []\n",
    "\n",
    "    for input_file, mask_file in zip(input_files, mask_files):\n",
    "        # Read input file\n",
    "        with rasterio.open(input_file) as src:\n",
    "            img = src.read(2)  # Read the first band assuming it's a single-band image\n",
    "            # print(img)\n",
    "            images.append(img)\n",
    "\n",
    "        # Read mask file\n",
    "        with rasterio.open(mask_file) as src:\n",
    "            msk = src.read(1)  # Read the first band assuming it's a single-band image\n",
    "            masks.append(msk)\n",
    "\n",
    "    return np.array(images), np.array(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = './data/'\n",
    "mask_dir = './output_tif/'\n",
    "\n",
    "# Load data\n",
    "images, masks = load_data(input_dir, mask_dir)\n",
    "\n",
    "# Define input shape and number of classes\n",
    "images = np.expand_dims(images, axis=-1)\n",
    "input_shape = images.shape[1:]\n",
    "num_classes = 1  # Assuming binary segmentation, adjust accordingly if needed\n",
    "\n",
    "# Create and compile the model\n",
    "model = dense_unet(input_shape, num_classes)\n",
    "# for layer in model.layers:\n",
    "#     print(layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model/batch_normalization/FusedBatchNormV3' defined at (most recent call last):\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 390, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_42360\\486052249.py\", line 4, in <module>\n      model.fit(images, masks, epochs=10, batch_size=1)  # Adjust epochs and batch size as needed\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 850, in call\n      outputs = self._fused_batch_norm(inputs, training=training)\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 660, in _fused_batch_norm\n      output, mean, variance = control_flow_util.smart_cond(\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\keras\\utils\\control_flow_util.py\", line 108, in smart_cond\n      return tf.__internal__.smart_cond.smart_cond(\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 634, in _fused_batch_norm_training\n      return tf.compat.v1.nn.fused_batch_norm(\nNode: 'model/batch_normalization/FusedBatchNormV3'\nOOM when allocating tensor with shape[1,64,3008,4000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/batch_normalization/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_6102]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_42360\\486052249.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Adjust epochs and batch size as needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model/batch_normalization/FusedBatchNormV3' defined at (most recent call last):\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 390, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_42360\\486052249.py\", line 4, in <module>\n      model.fit(images, masks, epochs=10, batch_size=1)  # Adjust epochs and batch size as needed\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 850, in call\n      outputs = self._fused_batch_norm(inputs, training=training)\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 660, in _fused_batch_norm\n      output, mean, variance = control_flow_util.smart_cond(\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\keras\\utils\\control_flow_util.py\", line 108, in smart_cond\n      return tf.__internal__.smart_cond.smart_cond(\n    File \"c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 634, in _fused_batch_norm_training\n      return tf.compat.v1.nn.fused_batch_norm(\nNode: 'model/batch_normalization/FusedBatchNormV3'\nOOM when allocating tensor with shape[1,64,3008,4000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/batch_normalization/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_6102]"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(images, masks, epochs=10, batch_size=1)  # Adjust epochs and batch size as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(images, masks)\n",
    "\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
